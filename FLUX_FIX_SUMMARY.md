# Flux Audio Pipeline: Problem Analysis & Fixes

## The Problem You Had

**Symptoms:**
- âœ… Greeting audio working (ElevenLabs â†’ MP3 â†’ frontend audio â†’ speakers)
- âœ… Microphone capturing audio (AudioStreamer capturing PCM16)
- âœ… Backend receiving chunks (logs show "FIRST AUDIO CHUNK RECEIVED")
- âŒ **BUT**: Flux never got the audio (no Flux events in logs)
- âŒ No speech-to-text transcription happening
- âŒ No user â†’ Novo conversation loop working

**Root Cause:** Audio was being captured and arriving at the backend, but **never actually being sent to Flux WebSocket**.

---

## What Was Broken

### 1. **Socket.IO Event Name Mismatch**

**Frontend Code** (`app-realtime.js`):
```javascript
this.client.socket.emit('audio-stream', {  // âœ… Correct
  chunk: base64Chunk
});
```

**Old Backend Code** (`portal-server.js`):
```javascript
socket.on('audio-chunk', ...) // âŒ WRONG - listening for different event!
```

**Problem**: Frontend sending `audio-stream`, backend listening for `audio-chunk`. Chunks arrive but handler never fires.

**Fix Applied**:
```javascript
// In portal-client.js - New method:
sendAudioChunk(pcm16Uint8Array) {
  const base64 = btoa(binary);
  this.socket.emit('audio-stream', { chunk: base64 });  // âœ… Correct event + field
}

// In app-realtime.js - Use it:
this.client.sendAudioChunk(pcm16Data);  // âœ… Call new method

// In portal-server.js - Already listening:
socket.on('audio-stream', async (data) => {  // âœ… Now matches!
  let audioChunk = Buffer.from(data.chunk, 'base64');
  fluxState.send(audioChunk);  // âœ… Send to Flux
});
```

---

### 2. **Flux Endpoint URL Incorrect**

**Old Code**:
```javascript
this.baseUrl = 'wss://api.deepgram.com/v2';  // âŒ WRONG
const url = `${this.baseUrl}/listen?...`;    // âŒ Results in /v2/listen? (OK by accident)
```

**Better Code**:
```javascript
this.baseUrl = 'wss://api.deepgram.com/v2/listen';  // âœ… Full endpoint
const url = `${this.baseUrl}?...`;                   // âœ… Cleaner, explicit
```

**Why It Matters:**
Per Deepgram docs:
> "Flux requires the /v2/listen endpoint â€” Using /v1/listen will not work with Flux."

Clear, explicit URL prevents confusion.

---

### 3. **Missing Audio Format Parameters**

**Before**:
```javascript
const fluxConnection = await deepgramClient.connect({
  model: 'flux-general-en',
  tag: `novo-user-${socket.userName}` 
  // âŒ Missing: encoding, sample_rate (uses defaults, might be wrong)
});
```

**After**:
```javascript
const fluxConnection = await deepgramClient.connect({
  model: 'flux-general-en',
  encoding: 'linear16',      // âœ… Explicit - PCM16 binary
  sample_rate: 16000,        // âœ… Explicit - 16kHz (matches frontend)
  tag: `novo-user-${socket.userName}` 
});
```

**Why It Matters:**
Frontend captures audio @ 16kHz PCM16 (linear16). Must match exactly.

---

### 4. **Message Handler Set Too Late**

**Before**:
```javascript
const fluxConnection = await deepgramClient.connect(...);
// ... later, sometimes:
deepgramClient.setMessageHandler((msg) => {
  handleFluxMessage(msg, socket);
});
// âŒ If Flux sends events before handler set, they're lost!
```

**After**:
```javascript
const fluxConnection = await deepgramClient.connect(...);

// âœ… Set handler IMMEDIATELY after connection
deepgramClient.setMessageHandler((msg) => {
  handleFluxMessage(msg, socket);
});

// Then safe to send audio:
fluxState.send(audioChunk);
```

---

## How The Fix Works (End-to-End)

### 1. **Audio Captured**
- Frontend: Microphone â†’ AudioContext â†’ PCM16 (Uint8Array)
- Sample rate: 16kHz, Buffer: 1024 samples (64ms chunks)

### 2. **Audio Converted & Sent**
```javascript
// frontend: app-realtime.js
this.client.sendAudioChunk(pcm16Data);
  â†“
// portal-client.js
Uint8Array â†’ btoa() â†’ base64 string
socket.emit('audio-stream', { chunk: base64 })
  â†“
// WebSocket event to backend
```

### 3. **Backend Receives & Converts**
```javascript
// backend: portal-server.js
socket.on('audio-stream', async (data) => {
  let audioChunk = Buffer.from(data.chunk, 'base64');  // âœ… Binary again
  // audioChunk is now raw PCM16 bytes
```

### 4. **Flux Connection Created (Once)**
```javascript
if (!fluxState) {
  const fluxConnection = await deepgramClient.connect({
    model: 'flux-general-en',
    encoding: 'linear16',
    sample_rate: 16000
  });
  // âœ… WebSocket established
  deepgramClient.setMessageHandler(handleFluxMessage);
  // âœ… Handler ready BEFORE audio
```

### 5. **Audio Sent to Flux**
```javascript
fluxState.send(audioChunk);
  â†“
// WebSocket.send(Buffer)
  â†“
// Deepgram Flux receives binary audio
// Starts processing: StartOfTurn â†’ Update â†’ EndOfTurn
```

### 6. **Flux Events Received & Processed**
```javascript
handleFluxMessage(msg, socket) {
  switch (msg.event) {
    case 'StartOfTurn':
      console.log('User started speaking');
      
    case 'Update':
      // Partial transcription
      socket.emit('transcription-partial', { text: msg.transcript });
      
    case 'EndOfTurn':
      // Full transcription with high confidence
      socket.emit('transcription-final', { text: msg.transcript });
      getNovoResponse(msg.transcript, socket);  // âœ… Ask Novo for response
```

### 7. **Response Generated**
```javascript
getNovoResponse(userText, socket) {
  // HTTP POST to bridge (:3002)
  // Returns: { response: "I heard you say...", emotion: "neutral" }
  // âœ… Then synthesize + play
```

---

## Key Debugging Flags

When testing, watch for these log messages:

### âœ… Expected (Working)
```
ğŸ“¥ FIRST AUDIO CHUNK RECEIVED from User (Flux enabled: true)
   Chunk size: 1024 bytes
ğŸ“¤ FIRST AUDIO CHUNK SENT TO FLUX
âœ… Connected to Deepgram Flux
ğŸ¤ Flux: StartOfTurn - user began speaking
ğŸ“ Flux: Update - "hello there"...
ğŸ›‘ Flux: EndOfTurn (high confidence) - "hello there" (Confidence: 92%)
```

### âŒ Problem Signals (Broken)
```
ğŸ“¥ FIRST AUDIO CHUNK RECEIVED  (but no matching SENT TO FLUX)
  â†’ Flux connection not being made

âœ… Connected to Deepgram Flux  (but no StartOfTurn event)
  â†’ Audio not reaching Flux, or wrong format

No 'audio-stream' events in backend logs
  â†’ Frontend sending different event name
```

---

## Files Modified

1. **`/root/clawd/avatar-portal/code/js/portal-client.js`**
   - Added `sendAudioChunk()` method (correct event + field names)
   - Kept `sendAudio()` for backwards compatibility

2. **`/root/clawd/avatar-portal/code/js/app-realtime.js`**
   - Changed to call `this.client.sendAudioChunk()` instead of direct emit

3. **`/root/clawd/avatar-portal/portal-server.js`**
   - Enhanced audio-stream handler with detailed debugging
   - Added explicit `encoding` and `sample_rate` parameters
   - Set message handler BEFORE sending audio
   - Added tracking: chunksSent, bytesTotal, duration estimate

4. **`/root/clawd/deepgram-flux-service.js`**
   - Changed base URL to `/v2/listen` (explicit full endpoint)
   - Clarified parameter handling

---

## Next Steps

1. **Test the flow**: Open https://novopresent.com, click Start, say something
2. **Check logs**: Should see "FIRST AUDIO CHUNK SENT TO FLUX"
3. **Verify Flux events**: Should see StartOfTurn â†’ Update â†’ EndOfTurn
4. **Full loop**: Flux transcription â†’ bridge response â†’ TTS â†’ audio playback
5. **Optimize**: Consider adjusting chunk size to 2560 bytes (80ms, Flux recommendation)

---

**Status**: Flux audio pipeline debugging complete. Ready for end-to-end testing.
